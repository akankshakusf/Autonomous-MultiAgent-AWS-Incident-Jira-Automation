{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autonomous Incident Response System for AWS\n",
    "---\n",
    "\n",
    "In this project, we will build an Agentic system to respond to incidents in your AWS accounts. This is a multi-agent system that composes 4 main components: \n",
    "\n",
    "1. **Monitoring**: This composes of a tool that enables the agent to get CloudWatch logs from a user account based on their service of interest.\n",
    "\n",
    "1. **Diagnosis**: This includes diagnosis events that are seen through the monitoring agent. The diagnosis agent will fetch the information from the monitoring agent, use a web search tool to look for remediations, create a report and then use that report in the next resolution agent.\n",
    "\n",
    "1. **Resolution**: This portion of the solution will be triggered by a diagnosis done from the step before. Once the diagnoses is done with the clear report, then the content of the report is used in the description of the JIRA ticket that the agent creates.\n",
    "\n",
    "This solution will also contain aspects for observability and tracing but without further ado, let's get right into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import environment variables\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]= os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "\n",
    "# Access them in code\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "os.environ[\"AWS_REGION\"] = os.getenv(\"AWS_REGION\")\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"JIRA_API_TOKEN\"] = os.getenv(\"JIRA_API_TOKEN\")\n",
    "os.environ[\"JIRA_USERNAME\"] = os.getenv(\"JIRA_USERNAME\")\n",
    "os.environ[\"JIRA_INSTANCE_URL\"] = os.getenv(\"JIRA_INSTANCE_URL\")\n",
    "os.environ[\"JIRA_CLOUD\"] = \"True\"\n",
    "os.environ['PROJECT_KEY'] = os.getenv(\"PROJECT_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import general packages \n",
    "import boto3\n",
    "import logging \n",
    "import json\n",
    "import re\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from typing import Annotated, List, Dict, Any, Optional, Union, Literal\n",
    "from typing_extensions import TypedDict\n",
    "from langsmith import traceable\n",
    "\n",
    "#import langgraph relavant packages \n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "#checkpointing for agent memory \n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.types import Command\n",
    "\n",
    "#langchain imports\n",
    "from langchain_aws.chat_models import ChatBedrockConverse\n",
    "from langchain_core.tools import BaseTool, tool\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.utilities import JiraAPIWrapper\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain.tools import Tool\n",
    " \n",
    "#langsmith import \n",
    "from langsmith import Client\n",
    "from langsmith import traceable\n",
    "\n",
    "from colorama import init, Fore, Style\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Formatting per requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize colorama\n",
    "init()\n",
    "\n",
    "# Set up a logger for pretty printing\n",
    "logger = logging.getLogger(\"aws_monitoring_workflow\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Remove any existing handlers to avoid duplicate logs\n",
    "if logger.hasHandlers():\n",
    "    for handler in logger.handlers:\n",
    "        logger.removeHandler(handler)\n",
    "\n",
    "# Add a new handler with formatting\n",
    "handler = logging.StreamHandler()\n",
    "formatter = logging.Formatter('%(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "def pretty_print_messages(node_output):\n",
    "    \"\"\"Format and print only essential messages: tools, AI responses, and agent names.\"\"\"\n",
    "    if isinstance(node_output, dict) and \"messages\" in node_output:\n",
    "        messages = node_output[\"messages\"]\n",
    "        for msg in messages:\n",
    "            # Skip any error-related messages\n",
    "            if isinstance(msg, dict):  # Handle dict-formatted messages\n",
    "                role = msg.get(\"role\", \"\")\n",
    "                content = msg.get(\"content\", \"\")\n",
    "                \n",
    "                # Only print AI messages\n",
    "                if role == \"assistant\" or role == \"ai\":\n",
    "                    logger.info(f\"{Fore.BLUE}[AI] {content}{Style.RESET_ALL}\")\n",
    "                # Only print tool calls\n",
    "                elif role == \"tool\":\n",
    "                    tool_name = msg.get(\"name\", \"tool\")\n",
    "                    logger.info(f\"{Fore.YELLOW}[TOOL: {tool_name}] Called{Style.RESET_ALL}\")\n",
    "            \n",
    "            # Handle LangChain message objects\n",
    "            elif isinstance(msg, (AIMessage, ToolMessage)):\n",
    "                if isinstance(msg, AIMessage):\n",
    "                    logger.info(f\"{Fore.BLUE}[AI] {msg.content}{Style.RESET_ALL}\")\n",
    "                elif isinstance(msg, ToolMessage):\n",
    "                    logger.info(f\"{Fore.YELLOW}[TOOL: {msg.name}] Called{Style.RESET_ALL}\")\n",
    "    \n",
    "    # Print the agent name if available\n",
    "    if isinstance(node_output, dict) and \"agent_name\" in node_output:\n",
    "        logger.info(f\"{Fore.MAGENTA}[AGENT: {node_output['agent_name']}]{Style.RESET_ALL}\")\n",
    "    \n",
    "    # For supervisor or other non-message nodes\n",
    "    if isinstance(node_output, dict) and \"node_type\" in node_output:\n",
    "        logger.info(f\"{Fore.CYAN}[NODE: {node_output['node_type']}]{Style.RESET_ALL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model constants\n",
    "AMAZON_NOVA_PRO_MODEL_ID: str = 'us.amazon.nova-pro-v1:0'\n",
    "AMAZON_NOVA_MICRO_MODEL_ID: str = 'us.amazon.nova-micro-v1:0'\n",
    "META_LLAMA_3_2_11B_VISION_INSTRUCT: str = 'us.meta.llama3-2-11b-instruct-v1:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State definitions\n",
    "---\n",
    "\n",
    "First, we will define the state for our sub agents: for Monitoring, Diagnosis, Remediation and the Supervisor. Since all of these will have similar states, let's go ahead and define a common `incidentState`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IncidentState(TypedDict):\n",
    "    \"\"\"\n",
    "    A state in LangGraph is a shared data structure, typically a TypedDict or a Pydantic\n",
    "    model that represents the current snapshot of your application and allows nodes to communicate and \n",
    "    exchange data by reading and writing to it.\n",
    "    \"\"\"\n",
    "    messages: List[BaseMessage]\n",
    "    alarms: Optional[List[Dict]]\n",
    "    metrics: Optional[Dict]\n",
    "    instance_ids: Optional[List[str]]\n",
    "    diagnosis_report: Optional[str]\n",
    "    remediation_actions: Optional[List[str]]\n",
    "    notification_status: Optional[str]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the help of this unified state, this does as follows:\n",
    "\n",
    "1. **Ensures consistency**: Each agent in this case works with a consistent structure.\n",
    "\n",
    "1. **Ease of communication**: This facilitates simpler data passing between nodes.\n",
    "\n",
    "1. **Traceability**: Incident lifecycle remains centralized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized the LLM: client=<botocore.client.BedrockRuntime object at 0x7f9c029f2fc0> model_id='us.amazon.nova-micro-v1:0' temperature=0.1 aws_access_key_id=SecretStr('**********') aws_secret_access_key=SecretStr('**********') provider='amazon' supports_tool_choice_values=('auto', 'any', 'tool')\n"
     ]
    }
   ],
   "source": [
    "# let's define the LLM that will be used in the monitoring agent\n",
    "llm = ChatBedrockConverse(\n",
    "    model_id = AMAZON_NOVA_MICRO_MODEL_ID, \n",
    "    temperature = 0.1,\n",
    ")\n",
    "\n",
    "logger.info(f\"Initialized the LLM: {llm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define monitoring tools\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "# Set up logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define boto3 and AWS clients\n",
    "cloudwatch_client = boto3.client('cloudwatch')\n",
    "cloudtrail_client = boto3.client('cloudtrail')\n",
    "logs_client = boto3.client('logs')\n",
    "xray_client = boto3.client('xray')\n",
    "autoscaling_client = boto3.client('autoscaling')\n",
    "ec2_client = boto3.client('ec2')\n",
    "health_client = boto3.client('health')\n",
    "\n",
    "\n",
    "class FetchLogsInput(BaseModel):\n",
    "    service_name: str\n",
    "    days: Optional[int] = 3\n",
    "    filter_pattern: Optional[str] = \"\"\n",
    "\n",
    "@traceable(run_type=\"tool\", name=\"fetch_cloudwatch_logs_for_service\")\n",
    "def fetch_cloudwatch_logs_for_service(\n",
    "    service_name: str,\n",
    "    days: int = 3,\n",
    "    filter_pattern: str = \"\"\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fetches CloudWatch logs for a specified service for the given number of days.\n",
    "    \n",
    "    Args:\n",
    "        service_name (str): The name of the service to fetch logs for (e.g., \"ec2\", \"lambda\", \"rds\")\n",
    "        days (int): Number of days of logs to fetch (default: 3)\n",
    "        filter_pattern (str): Optional CloudWatch Logs filter pattern\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with log groups and their recent log events\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Map service name to potential log group prefixes\n",
    "        service_log_prefixes = {\n",
    "            \"ec2\": [\"/aws/ec2\", \"/var/log\"],\n",
    "            \"lambda\": [\"/aws/lambda\"],\n",
    "            \"rds\": [\"/aws/rds\"],\n",
    "            \"eks\": [\"/aws/eks\"],\n",
    "            \"apigateway\": [\"/aws/apigateway\"],\n",
    "            \"cloudtrail\": [\"/aws/cloudtrail\"],\n",
    "            \"s3\": [\"/aws/s3\", \"/aws/s3-access\"],\n",
    "            \"vpc\": [\"/aws/vpc\"],\n",
    "            \"waf\": [\"/aws/waf\"],\n",
    "            \"bedrock\": [\"/bedrockInvocationlogs\"], \n",
    "            \"iam\": ['/aws/cloudtrail']\n",
    "        }\n",
    "        \n",
    "        # Default to searching all log groups if service isn't in our mapping\n",
    "        prefixes = service_log_prefixes.get(service_name.lower(), [\"\"])\n",
    "        print(f\"Fetching logs for the service: {prefixes}\")\n",
    "        \n",
    "        # Find all log groups for this service\n",
    "        log_groups = []\n",
    "        for prefix in prefixes:\n",
    "            paginator = logs_client.get_paginator('describe_log_groups')\n",
    "            for page in paginator.paginate(logGroupNamePrefix=prefix):\n",
    "                log_groups.extend([group['logGroupName'] for group in page['logGroups']])\n",
    "        \n",
    "        if not log_groups:\n",
    "            return {\"status\": \"warning\", \"message\": f\"No log groups found for service: {service_name}\"}\n",
    "        \n",
    "        # Calculate time range\n",
    "        ##end_time = datetime.utcnow()\n",
    "        end_time = datetime.now(timezone.utc)\n",
    "        start_time = end_time - timedelta(days=days)\n",
    "        \n",
    "        # Convert to milliseconds since epoch\n",
    "        start_time_ms = int(start_time.timestamp() * 1000)\n",
    "        end_time_ms = int(end_time.timestamp() * 1000)\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Iterate through log groups and fetch log events\n",
    "        for log_group in log_groups:\n",
    "            try:\n",
    "                # First get log streams\n",
    "                response = logs_client.describe_log_streams(\n",
    "                    logGroupName=log_group,\n",
    "                    orderBy='LastEventTime',\n",
    "                    descending=True,\n",
    "                    limit=5  # Get the 5 most recent streams\n",
    "                )\n",
    "                print(f\"fetching logs for log group {log_group}: {response}\")\n",
    "                streams = response.get('logStreams', [])\n",
    "                \n",
    "                if not streams:\n",
    "                    results[log_group] = {\"status\": \"info\", \"message\": \"No log streams found\"}\n",
    "                    continue\n",
    "                \n",
    "                group_events = []\n",
    "                \n",
    "                # For each stream, get recent log events\n",
    "                for stream in streams:\n",
    "                    stream_name = stream['logStreamName']\n",
    "                    \n",
    "                    # If filter pattern is provided, use filter_log_events\n",
    "                    if filter_pattern:\n",
    "                        filter_response = logs_client.filter_log_events(\n",
    "                            logGroupName=log_group,\n",
    "                            logStreamNames=[stream_name],\n",
    "                            startTime=start_time_ms,\n",
    "                            endTime=end_time_ms,\n",
    "                            filterPattern=filter_pattern,\n",
    "                            limit=100\n",
    "                        )\n",
    "                        events = filter_response.get('events', [])\n",
    "                    else:\n",
    "                        # Otherwise use get_log_events\n",
    "                        log_response = logs_client.get_log_events(\n",
    "                            logGroupName=log_group,\n",
    "                            logStreamName=stream_name,\n",
    "                            startTime=start_time_ms,\n",
    "                            endTime=end_time_ms,\n",
    "                            limit=100\n",
    "                        )\n",
    "                        events = log_response.get('events', [])\n",
    "                    \n",
    "                    # Process and add events\n",
    "                    for event in events:\n",
    "                        # Convert timestamp to readable format\n",
    "                        timestamp = datetime.fromtimestamp(event['timestamp'] / 1000)\n",
    "                        formatted_event = {\n",
    "                            'timestamp': timestamp.isoformat(),\n",
    "                            'message': event['message']\n",
    "                        }\n",
    "                        group_events.append(formatted_event)\n",
    "                \n",
    "                # Sort all events by timestamp (newest first)\n",
    "                group_events.sort(key=lambda x: x['timestamp'], reverse=True)\n",
    "                \n",
    "                results[log_group] = {\n",
    "                    \"status\": \"success\",\n",
    "                    \"events_count\": len(group_events),\n",
    "                    \"events\": group_events[:100]  # Limit to 100 most recent events\n",
    "                }\n",
    "                \n",
    "            except Exception as e:\n",
    "                results[log_group] = {\"status\": \"error\", \"message\": str(e)}\n",
    "        \n",
    "        return {\n",
    "            \"service\": service_name,\n",
    "            \"time_range\": f\"{start_time.isoformat()} to {end_time.isoformat()}\",\n",
    "            \"log_groups_count\": len(log_groups),\n",
    "            \"log_groups\": results\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching logs for service {service_name}: {e}\")\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the function into a Tool object so the agent can call it correctly\n",
    "\n",
    "fetch_logs_tool = Tool.from_function(\n",
    "    func=fetch_cloudwatch_logs_for_service,\n",
    "    name=\"fetch_cloudwatch_logs_for_service\",\n",
    "    description=\"Fetch CloudWatch logs for a specified AWS service. You can provide days and optional filter pattern.\",\n",
    "    args_schema=FetchLogsInput\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitoring_toolkit = [fetch_logs_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the monitoring agent.\n",
    "# We will create a Reason and Act agent from langchain that will be able to break down the problem \n",
    "# into specific tasks and will be able to determine which tool to call.\n",
    "monitoring_system_prompt = \"\"\"\n",
    "You are the AWS CloudWatch Logs Monitoring Agent, specialized in retrieving and analyzing log data.\n",
    "\n",
    "When a user provides a service name (e.g., \"iam\",\"EC2\", \"Lambda\", \"RDS\"), your responsibilities include:\n",
    "\n",
    "1. Fetch CloudWatch logs for the specified AWS service using the fetch_cloudwatch_logs_for_service tool\n",
    "2. Analyze the retrieved logs to identify:\n",
    "   - Error patterns and exceptions\n",
    "   - Performance issues or slowdowns\n",
    "   - Security-related events (authorization failures, access denials)\n",
    "   - Unusual activity or potential anomalies\n",
    "   - Service outages or degradations\n",
    "\n",
    "3. When filter patterns are specified, use them to find specific types of log entries\n",
    "4. Present the logs in a structured, chronological manner\n",
    "5. Provide a concise summary of key findings, particularly highlighting:\n",
    "   - Critical errors that need immediate attention\n",
    "   - Security concerns or suspicious activities\n",
    "   - Performance bottlenecks\n",
    "   - Unusual patterns that might indicate problems\n",
    "\n",
    "When reporting:\n",
    "1. Start with a high-level summary of what you found\n",
    "2. Include specific log examples that illustrate important issues\n",
    "3. Organize information by log group and timestamp\n",
    "4. Prioritize recent and critical events\n",
    "\n",
    "Ensure you ask for all required parameters:\n",
    "- The service name to analyze (required)\n",
    "- The number of days of logs to examine (optional, default is 3)\n",
    "- Any specific filter patterns to apply (optional)\n",
    "\n",
    "Be thorough in your analysis but concise in your reporting.\n",
    "Mark your work as complete by saying \"MONITORING COMPLETE\" at the end of your response.\n",
    "Do not call tools again once this message is produced.\n",
    "End your reply by saying: `MONITORING COMPLETE` exactly. This is mandatory.\n",
    "\"\"\"\n",
    "monitoring_agent = create_react_agent(llm, tools=monitoring_toolkit, prompt=monitoring_system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable tracing with LangSmith\n",
    "---\n",
    "\n",
    "LangSmith is an all-in-one developer platform for every step of the LLM-powered application lifecycle, whether you’re building with LangChain or not.\n",
    "Debug, collaborate, test, and monitor your LLM applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitoring_node(state: Dict , config: Optional[Dict] = None) -> Dict:\n",
    "    \"\"\"Monitoring agent node to check AWS service status.\"\"\"\n",
    "    # Retrieve the current messages from state (defaulting to an empty list if missing)\n",
    "    messages = state.get(\"messages\", [])\n",
    "    \n",
    "    # Invoke the monitoring agent with the current messages\n",
    "    response = monitoring_agent.invoke({\"messages\": messages})\n",
    "    \n",
    "    # Process the agent's response to extract content and create an AIMessage\n",
    "    if hasattr(response, \"content\"):\n",
    "        content = response.content\n",
    "        ai_message = response\n",
    "    elif isinstance(response, str):\n",
    "        content = response\n",
    "        ai_message = AIMessage(content=content)\n",
    "    elif isinstance(response, dict) and \"content\" in response:\n",
    "        content = response[\"content\"]\n",
    "        ai_message = AIMessage(content=content)\n",
    "    else:\n",
    "        content = str(response)\n",
    "        ai_message = AIMessage(content=content)\n",
    "    \n",
    "    # Retrieve or initialize the workflow state, and update the monitoring flag\n",
    "    workflow_state = state.get(\"workflow\", {})\n",
    "    workflow_state[\"monitoring_complete\"] = \"MONITORING COMPLETE\" in content\n",
    "    \n",
    "    # Optionally, update other fields in your state (e.g., diagnosis_report, alarms) based on content\n",
    "    \n",
    "    # Return the updated state with the new message appended and the workflow state updated\n",
    "    return {\n",
    "        \"messages\": messages + [ai_message],\n",
    "        \"workflow\": workflow_state,\n",
    "        \"monitoring_complete\": workflow_state[\"monitoring_complete\"]  # ← this fixes the routing issue\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='\\nI want to check IAM logs for the last 2 days to identify any potential security issues or compliance violations in my AWS account.\\n', additional_kwargs={}, response_metadata={}, id='477077a9-66fd-4b88-a341-46ea861cf102'), AIMessage(content=[{'type': 'text', 'text': '<thinking> The user wants to analyze IAM logs for the last 2 days to identify potential security issues or compliance violations. To do this, I will use the `fetch_cloudwatch_logs_for_service` tool to retrieve the logs for the IAM service, specifying the number of days as 2. I will not provide a filter pattern at this stage to get a comprehensive view of all logs. After fetching the logs, I will analyze them for any security-related events such as authorization failures, access denials, or any other suspicious activities. Finally, I will present the logs in a structured manner and provide a summary of key findings. </thinking>\\n\\n'}, {'type': 'tool_use', 'name': 'fetch_cloudwatch_logs_for_service', 'input': {'filter_pattern': '', 'service_name': 'iam', 'days': 2}, 'id': 'tooluse_2A7YZWkhSXSngd4fSJzMDQ'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '9e6fac24-a068-4e27-97f1-1079f8b39229', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Tue, 17 Jun 2025 14:27:28 GMT', 'content-type': 'application/json', 'content-length': '985', 'connection': 'keep-alive', 'x-amzn-requestid': '9e6fac24-a068-4e27-97f1-1079f8b39229'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [908]}, 'model_name': 'us.amazon.nova-micro-v1:0'}, id='run--374ffd75-6c47-4642-9044-ee882242d294-0', tool_calls=[{'name': 'fetch_cloudwatch_logs_for_service', 'args': {'filter_pattern': '', 'service_name': 'iam', 'days': 2}, 'id': 'tooluse_2A7YZWkhSXSngd4fSJzMDQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 849, 'output_tokens': 173, 'total_tokens': 1022, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), ToolMessage(content='Error: ToolException(\"Too many arguments to single-input tool fetch_cloudwatch_logs_for_service.\\\\n                Consider using StructuredTool instead. Args: [\\'iam\\', 2, \\'\\']\")\\n Please fix your mistakes.', name='fetch_cloudwatch_logs_for_service', id='191b17e1-3886-48f5-871e-5ef14bfb92a5', tool_call_id='tooluse_2A7YZWkhSXSngd4fSJzMDQ', status='error'), AIMessage(content=[{'type': 'text', 'text': '<thinking> It seems there was an error due to incorrect usage of the `fetch_cloudwatch_logs_for_service` tool. The tool expects the arguments in a specific format, but I provided them in a different way. I will now correctly format the arguments to match the expected input format. </thinking> '}, {'type': 'tool_use', 'name': 'fetch_cloudwatch_logs_for_service', 'input': {'filter_pattern': '', 'service_name': 'iam', 'days': 2}, 'id': 'tooluse_ZnxbKGaWR0GV9x8SkP5uOw'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '5de8eeb9-ec90-4fc1-9486-4e20e6498552', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Tue, 17 Jun 2025 14:27:29 GMT', 'content-type': 'application/json', 'content-length': '642', 'connection': 'keep-alive', 'x-amzn-requestid': '5de8eeb9-ec90-4fc1-9486-4e20e6498552'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [614]}, 'model_name': 'us.amazon.nova-micro-v1:0'}, id='run--06f3efb8-f2a8-43b9-91ce-fefb3aac7b6c-0', tool_calls=[{'name': 'fetch_cloudwatch_logs_for_service', 'args': {'filter_pattern': '', 'service_name': 'iam', 'days': 2}, 'id': 'tooluse_ZnxbKGaWR0GV9x8SkP5uOw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1107, 'output_tokens': 101, 'total_tokens': 1208, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), ToolMessage(content='Error: ToolException(\"Too many arguments to single-input tool fetch_cloudwatch_logs_for_service.\\\\n                Consider using StructuredTool instead. Args: [\\'iam\\', 2, \\'\\']\")\\n Please fix your mistakes.', name='fetch_cloudwatch_logs_for_service', id='7bfd527e-bef8-4b2c-826f-c11710c76bc3', tool_call_id='tooluse_ZnxbKGaWR0GV9x8SkP5uOw', status='error'), AIMessage(content=[{'type': 'text', 'text': '<thinking> It appears that the tool still has issues with the argument format. Given the error message, it seems the tool expects a single input string that includes all the necessary parameters. I will now construct a single input string that includes the service name, the number of days, and the filter pattern (which is empty in this case). </thinking> '}, {'type': 'tool_use', 'name': 'fetch_cloudwatch_logs_for_service', 'input': {'filter_pattern': '', 'service_name': 'iam', 'days': 2}, 'id': 'tooluse__6AN6BsiTR6MgAmVHIz-bw'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '647681c5-37c9-43b1-8bc2-dce10a89a421', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Tue, 17 Jun 2025 14:27:30 GMT', 'content-type': 'application/json', 'content-length': '705', 'connection': 'keep-alive', 'x-amzn-requestid': '647681c5-37c9-43b1-8bc2-dce10a89a421'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [658]}, 'model_name': 'us.amazon.nova-micro-v1:0'}, id='run--f926c7bb-3f09-48c2-b090-94e3981e4d86-0', tool_calls=[{'name': 'fetch_cloudwatch_logs_for_service', 'args': {'filter_pattern': '', 'service_name': 'iam', 'days': 2}, 'id': 'tooluse__6AN6BsiTR6MgAmVHIz-bw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1293, 'output_tokens': 106, 'total_tokens': 1399, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), ToolMessage(content='Error: ToolException(\"Too many arguments to single-input tool fetch_cloudwatch_logs_for_service.\\\\n                Consider using StructuredTool instead. Args: [\\'iam\\', 2, \\'\\']\")\\n Please fix your mistakes.', name='fetch_cloudwatch_logs_for_service', id='c34b79e6-49ff-4e30-aaf3-a3c0501b1cf8', tool_call_id='tooluse__6AN6BsiTR6MgAmVHIz-bw', status='error'), AIMessage(content=[{'type': 'text', 'text': '<thinking> It seems there is still an issue with the argument format for the `fetch_cloudwatch_logs_for_service` tool. Given the error message, it appears that the tool expects a single input string that encapsulates all parameters. I will now try to format the input as a single string in the correct format. </thinking> '}, {'type': 'tool_use', 'name': 'fetch_cloudwatch_logs_for_service', 'input': {'filter_pattern': '', 'service_name': 'iam', 'days': 2}, 'id': 'tooluse_X-Lnl_weToy31dHiOPS76w'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '1c4d28dd-b55e-4b17-9b9c-6e3c952e0eff', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Tue, 17 Jun 2025 14:27:30 GMT', 'content-type': 'application/json', 'content-length': '670', 'connection': 'keep-alive', 'x-amzn-requestid': '1c4d28dd-b55e-4b17-9b9c-6e3c952e0eff'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [673]}, 'model_name': 'us.amazon.nova-micro-v1:0'}, id='run--233f79f3-aedc-4a6a-85d2-848b708ea49c-0', tool_calls=[{'name': 'fetch_cloudwatch_logs_for_service', 'args': {'filter_pattern': '', 'service_name': 'iam', 'days': 2}, 'id': 'tooluse_X-Lnl_weToy31dHiOPS76w', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1484, 'output_tokens': 107, 'total_tokens': 1591, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), ToolMessage(content='Error: ToolException(\"Too many arguments to single-input tool fetch_cloudwatch_logs_for_service.\\\\n                Consider using StructuredTool instead. Args: [\\'iam\\', 2, \\'\\']\")\\n Please fix your mistakes.', name='fetch_cloudwatch_logs_for_service', id='161a1831-08d7-460e-9723-cb91d40045b5', tool_call_id='tooluse_X-Lnl_weToy31dHiOPS76w', status='error'), AIMessage(content=[{'type': 'text', 'text': \"<thinking> It seems there is a persistent issue with the argument format for the `fetch_cloudwatch_logs_for_service` tool. The error message indicates that the tool expects a single input string that encapsulates all parameters. However, the tool seems to be interpreting the arguments incorrectly. Since the tool's documentation suggests using a StructuredTool instead, I will attempt to use a structured input format that the tool can interpret correctly. </thinking> \"}, {'type': 'tool_use', 'name': 'fetch_cloudwatch_logs_for_service', 'input': {'input': {'days': 2, 'service_name': 'iam', 'filter_pattern': ''}}, 'id': 'tooluse_pxfSxybzT0KTrIh1wSbZVQ'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '49b80364-4d7a-425f-8c7c-62885ab0602e', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Tue, 17 Jun 2025 14:27:31 GMT', 'content-type': 'application/json', 'content-length': '828', 'connection': 'keep-alive', 'x-amzn-requestid': '49b80364-4d7a-425f-8c7c-62885ab0602e'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [846]}, 'model_name': 'us.amazon.nova-micro-v1:0'}, id='run--186b525a-89d2-442e-a84d-b06a558abfd7-0', tool_calls=[{'name': 'fetch_cloudwatch_logs_for_service', 'args': {'input': {'days': 2, 'service_name': 'iam', 'filter_pattern': ''}}, 'id': 'tooluse_pxfSxybzT0KTrIh1wSbZVQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1676, 'output_tokens': 138, 'total_tokens': 1814, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), ToolMessage(content=\"Error: 1 validation error for FetchLogsInput\\nservice_name\\n  Field required [type=missing, input_value={'input': {'days': 2, 'se..., 'filter_pattern': ''}}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\\n Please fix your mistakes.\", name='fetch_cloudwatch_logs_for_service', id='b6d6b564-1019-4905-a993-642782195c78', tool_call_id='tooluse_pxfSxybzT0KTrIh1wSbZVQ', status='error'), AIMessage(content=[{'type': 'text', 'text': \"<thinking> The error message indicates that the `service_name` field is missing from the input. It seems the tool expects the parameters in a specific structured format, but it looks like the way I'm passing the parameters is not being interpreted correctly. I will now try to pass the parameters in a way that matches the expected input structure, ensuring that all required fields are included. </thinking> \"}, {'type': 'tool_use', 'name': 'fetch_cloudwatch_logs_for_service', 'input': {'input': {'service_name': 'iam', 'days': 2, 'filter_pattern': ''}}, 'id': 'tooluse_n_xS4Xj7RY6sF8kW97xHmw'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '52917dd7-e608-4dfd-a987-336aee5c8bda', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Tue, 17 Jun 2025 14:27:32 GMT', 'content-type': 'application/json', 'content-length': '767', 'connection': 'keep-alive', 'x-amzn-requestid': '52917dd7-e608-4dfd-a987-336aee5c8bda'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [823]}, 'model_name': 'us.amazon.nova-micro-v1:0'}, id='run--9e0ed70f-d034-407b-8426-19d13169359e-0', tool_calls=[{'name': 'fetch_cloudwatch_logs_for_service', 'args': {'input': {'service_name': 'iam', 'days': 2, 'filter_pattern': ''}}, 'id': 'tooluse_n_xS4Xj7RY6sF8kW97xHmw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1932, 'output_tokens': 124, 'total_tokens': 2056, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), ToolMessage(content=\"Error: 1 validation error for FetchLogsInput\\nservice_name\\n  Field required [type=missing, input_value={'input': {'service_name'..., 'filter_pattern': ''}}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\\n Please fix your mistakes.\", name='fetch_cloudwatch_logs_for_service', id='b21de543-80e1-477b-b99f-4798fcc998cf', tool_call_id='tooluse_n_xS4Xj7RY6sF8kW97xHmw', status='error'), AIMessage(content=[{'type': 'text', 'text': '<thinking> It appears that there is still a misunderstanding in how the parameters are being passed to the `fetch_cloudwatch_logs_for_service` tool. The error message indicates that the `service_name` field is still missing, even though it was included in the input. Given the persistent issue, it seems the tool might be expecting the parameters in a different format than anticipated. I will attempt to pass the parameters in a straightforward manner without additional nesting to see if that resolves the issue. </thinking> '}, {'type': 'tool_use', 'name': 'fetch_cloudwatch_logs_for_service', 'input': {'filter_pattern': '', 'service_name': 'iam', 'days': 2}, 'id': 'tooluse_hCltHUdrT6W91slA-o2yhA'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '6a36764d-a15a-4ccb-9d1a-5b1b0a846a50', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Tue, 17 Jun 2025 14:27:33 GMT', 'content-type': 'application/json', 'content-length': '875', 'connection': 'keep-alive', 'x-amzn-requestid': '6a36764d-a15a-4ccb-9d1a-5b1b0a846a50'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [868]}, 'model_name': 'us.amazon.nova-micro-v1:0'}, id='run--5d02398f-237a-4db4-b484-59550cb877e2-0', tool_calls=[{'name': 'fetch_cloudwatch_logs_for_service', 'args': {'filter_pattern': '', 'service_name': 'iam', 'days': 2}, 'id': 'tooluse_hCltHUdrT6W91slA-o2yhA', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2172, 'output_tokens': 143, 'total_tokens': 2315, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), ToolMessage(content='Error: ToolException(\"Too many arguments to single-input tool fetch_cloudwatch_logs_for_service.\\\\n                Consider using StructuredTool instead. Args: [\\'iam\\', 2, \\'\\']\")\\n Please fix your mistakes.', name='fetch_cloudwatch_logs_for_service', id='b9162457-dcf7-4d2a-b200-d9da452011b9', tool_call_id='tooluse_hCltHUdrT6W91slA-o2yhA', status='error'), AIMessage(content=[{'type': 'text', 'text': \"<thinking> The error persists, indicating that the tool is still not interpreting the arguments correctly. Given the error message, it seems the tool expects a single input string that encapsulates all parameters, but it's not clear what the exact format should be. Since direct argument passing continues to fail, I will attempt to provide the parameters in a format that mimics a single input string, hoping that this will be interpreted correctly by the tool. </thinking> \"}, {'type': 'tool_use', 'name': 'fetch_cloudwatch_logs_for_service', 'input': {'input': 'days=2;service_name=iam;filter_pattern='}, 'id': 'tooluse_PWWIuZqVSJqJXc_cr_i1lw'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '9bfefe17-437f-4377-95a1-73bb084cfd08', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Tue, 17 Jun 2025 14:27:34 GMT', 'content-type': 'application/json', 'content-length': '823', 'connection': 'keep-alive', 'x-amzn-requestid': '9bfefe17-437f-4377-95a1-73bb084cfd08'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [867]}, 'model_name': 'us.amazon.nova-micro-v1:0'}, id='run--977a6b18-6178-4ad3-aaec-27ae61f67d15-0', tool_calls=[{'name': 'fetch_cloudwatch_logs_for_service', 'args': {'input': 'days=2;service_name=iam;filter_pattern='}, 'id': 'tooluse_PWWIuZqVSJqJXc_cr_i1lw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2400, 'output_tokens': 129, 'total_tokens': 2529, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), ToolMessage(content=\"Error: 1 validation error for FetchLogsInput\\nservice_name\\n  Field required [type=missing, input_value={'input': 'days=2;service...me=iam;filter_pattern='}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\\n Please fix your mistakes.\", name='fetch_cloudwatch_logs_for_service', id='edd077d7-bdca-4660-981d-b723d3447c38', tool_call_id='tooluse_PWWIuZqVSJqJXc_cr_i1lw', status='error'), AIMessage(content=\"<thinking> The error continues to indicate that the `service_name` field is missing, even though it was included in the input. It seems the tool is not interpreting the input string correctly. Given the persistent issue, it's clear that there is a misunderstanding in how the parameters should be formatted for this tool. Since direct argument passing and string formatting have both failed, I will need to clarify with the tool's documentation or support what the exact expected input format is. Unfortunately, without this information, I cannot proceed correctly. </thinking>\\n\\nI'm sorry, but it seems there is a persistent issue with the argument format for the `fetch_cloudwatch_logs_for_service` tool that I cannot resolve based on the current information available. I recommend checking the tool's documentation or contacting support for the correct input format to fetch the logs.\\n\\nMONITORING COMPLETE\", additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': 'b73582f2-01f3-41a6-95d1-880caaa574dc', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Tue, 17 Jun 2025 14:27:35 GMT', 'content-type': 'application/json', 'content-length': '1098', 'connection': 'keep-alive', 'x-amzn-requestid': 'b73582f2-01f3-41a6-95d1-880caaa574dc'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [1109]}, 'model_name': 'us.amazon.nova-micro-v1:0'}, id='run--bf551d55-b794-41fb-8338-495e00422109-0', usage_metadata={'input_tokens': 2646, 'output_tokens': 181, 'total_tokens': 2827, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]\n"
     ]
    }
   ],
   "source": [
    "content = \"\"\"\n",
    "I want to check IAM logs for the last 2 days to identify any potential security issues or compliance violations in my AWS account.\n",
    "\"\"\"\n",
    "\n",
    "# Invoke monitoring agent with the specific request for CloudTrail\n",
    "monitoring_response = monitoring_agent.invoke({\"messages\": [HumanMessage(content=content)]})\n",
    "print(monitoring_response[\"messages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define diagnosis tools\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define the LLM that will be used in the diagnosis agent. We will be using\n",
    "# the llama3.2 11b vision instruct model which will be capable of complex reasoning and \n",
    "# come up with a diagnosis plan\n",
    "\n",
    "diagnosis_llm = ChatBedrockConverse(\n",
    "    model_id = AMAZON_NOVA_PRO_MODEL_ID, \n",
    "    temperature = 0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize tavily search engine api \n",
    "tavily_search  = TavilySearchResults()\n",
    "\n",
    "\n",
    "# Helper function used inside the tool\n",
    "def search_each_line(state: Dict) -> str:\n",
    "    messages = state.get(\"messages\", [])\n",
    "    if not messages:\n",
    "        return \"No previous messages to review.\"\n",
    "    content = \"\"\n",
    "    last_msg = messages[-1]\n",
    "    if isinstance(last_msg, AIMessage):\n",
    "        content = last_msg.content\n",
    "    elif isinstance(last_msg, dict) and \"content\" in last_msg:\n",
    "        content = last_msg[\"content\"]\n",
    "    else:\n",
    "        return \"No valid monitoring content to search.\"\n",
    "\n",
    "    lines = [line.strip() for line in content.split(\"\\n\") if line.strip()]\n",
    "    aggregated_results = \"\"\n",
    "    for line in lines:\n",
    "        res = tavily_search.invoke({\"query\": line})\n",
    "        if isinstance(res, dict) and \"content\" in res:\n",
    "            aggregated_results += f\"- **{line}**: {res['content']}\\n\"\n",
    "        else:\n",
    "            aggregated_results += f\"- **{line}**: No results found.\\n\"\n",
    "\n",
    "    return aggregated_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Tavily Search Engine tool for the Agent to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def remediation_strategy_from_monitoring(state: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Extracts issues from monitoring agent's response and searches for remediation steps.\n",
    "    This node should be executed after the monitoring_node.\n",
    "    \"\"\"\n",
    "    # Get messages from state\n",
    "    messages = state.get(\"messages\", [])\n",
    "    \n",
    "    # Find the last AIMessage from the monitoring agent\n",
    "    monitoring_message = None\n",
    "    for msg in reversed(messages):\n",
    "        if isinstance(msg, AIMessage):\n",
    "            monitoring_message = msg\n",
    "            break\n",
    "    \n",
    "    if not monitoring_message:\n",
    "        # No monitoring message found\n",
    "        ai_message = AIMessage(content=\"No monitoring report found to search for remediation steps.\")\n",
    "        return {\n",
    "            \"messages\": messages + [ai_message],\n",
    "            \"workflow\": state.get(\"workflow\", {})\n",
    "        }\n",
    "    \n",
    "    # Use the enhanced search tool to find remediation steps\n",
    "    search_results = search_each_line({\"messages\": [monitoring_message]})\n",
    "    \n",
    "    # Create a new message with the search results\n",
    "    remediation_message = AIMessage(content=f\"\"\"\n",
    "### Remediation Recommendations\n",
    "\n",
    "Based on the monitoring report, here are potential remediation steps for each identified issue:\n",
    "\n",
    "{search_results}\n",
    "\n",
    "Please review these recommendations and implement the appropriate actions to address the security issues.\n",
    "\"\"\")\n",
    "    \n",
    "    # Update the workflow state\n",
    "    workflow_state = state.get(\"workflow\", {})\n",
    "    workflow_state[\"remediation_complete\"] = True\n",
    "    \n",
    "    # Return updated state\n",
    "    return {\n",
    "        \"messages\": messages + [remediation_message],\n",
    "        \"workflow\": workflow_state\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of diagnostic tools used to extract remediation strategies from monitoring data\n",
    "# This can be extended with more tools as needed\n",
    "diagnosis_toolkit = [remediation_strategy_from_monitoring]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_agent = create_react_agent(\n",
    "    diagnosis_llm,\n",
    "    tools=diagnosis_toolkit,\n",
    "    prompt=\"\"\"\n",
    "You are a specialized AWS diagnosis agent focused on identifying and addressing **security and compliance issues** based on log data.\n",
    "\n",
    "Your responsibilities:\n",
    "1. Analyze the log-based input you are provided this could include messages, alerts, or summaries from monitoring tools.\n",
    "2. Identify any known or potential **security misconfigurations**, **compliance violations**, or **anomalous activity**.\n",
    "3. Do not invent data — rely only on the log content given to you.\n",
    "4. Create a concise **Security & Compliance Diagnostic Report**. This report should include:\n",
    "   - Key findings\n",
    "   - Severity (e.g., High, Medium, Low)\n",
    "   - Potential risk or affected area\n",
    "5. If issues are found, use the **web search tool** to look up **remediation strategies** or best practices for resolving those issues.\n",
    "6. Present any helpful remediation guidance clearly under each issue found.\n",
    "\n",
    "Always be precise, evidence-based, and avoid assumptions.\n",
    "\n",
    "ALWAYS END YOUR RESPONSE WITH THE EXACT PHRASE:\n",
    "DIAGNOSIS COMPLETE\n",
    "(on a new line, exactly as written).\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnosis_node(state: Dict, **kwargs) -> Dict:\n",
    "    \"\"\"Diagnosis agent node to analyze root causes.\"\"\"\n",
    "    messages = state.get(\"messages\", [])\n",
    "    workflow = state.get(\"workflow\", {\n",
    "        \"current_step\": \"diagnosis_agent\",\n",
    "        \"monitoring_complete\": True,\n",
    "        \"diagnosis_complete\": False,\n",
    "        \"resolution_complete\": False\n",
    "    })\n",
    "    \n",
    "    # Invoke the diagnosis chain with the current messages\n",
    "    response = diagnosis_agent.invoke({\"messages\": messages})\n",
    "    \n",
    "    # Extract content from the response\n",
    "    if isinstance(response, dict) and \"messages\" in response:\n",
    "        ai_message = response[\"messages\"][-1]\n",
    "    elif hasattr(response, \"content\"):\n",
    "        ai_message = AIMessage(content=response.content)\n",
    "    elif isinstance(response, str):\n",
    "        ai_message = AIMessage(content=response)\n",
    "    else:\n",
    "        ai_message = AIMessage(content=str(response))\n",
    "    \n",
    "    # Make sure the response ends with the completion marker if not already there\n",
    "    if not ai_message.content.strip().upper().endswith(\"DIAGNOSIS COMPLETE\"):\n",
    "        ai_message = AIMessage(content=ai_message.content.strip() + \"\\n\\nDIAGNOSIS COMPLETE\")\n",
    "    \n",
    "    # Update messages with the AI message\n",
    "    new_messages = messages + [ai_message]\n",
    "    \n",
    "    return {\n",
    "        \"messages\": new_messages,\n",
    "        \"workflow\": workflow\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the diagnosis agents\n",
    "---\n",
    "\n",
    "Next, after we have defined our monitoring and diagnosis tools and created the agents, we can invoke to test how they work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content=' \\nHi, Generate a report on a user trying to break into my AWS account\\n', additional_kwargs={}, response_metadata={}, id='3c29d5f6-af44-4052-b40e-421c6b642329'), AIMessage(content=[{'type': 'text', 'text': '<thinking> To generate a report on a user attempting to break into an AWS account, I need to analyze log data for any signs of unauthorized access attempts. I will look for patterns such as multiple failed login attempts, unusual IP addresses, or attempts to access sensitive resources. Based on these findings, I will create a Security & Compliance Diagnostic Report. </thinking>\\n\\n'}, {'type': 'tool_use', 'name': 'remediation_strategy_from_monitoring', 'input': {'state': {'event': 'user attempting to break into AWS account'}}, 'id': 'tooluse_hkv-SR2TS32o5rsfppQyfg'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '115f6571-826c-4a64-937c-6091c633cf88', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Tue, 17 Jun 2025 12:25:22 GMT', 'content-type': 'application/json', 'content-length': '746', 'connection': 'keep-alive', 'x-amzn-requestid': '115f6571-826c-4a64-937c-6091c633cf88'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1601]}, 'model_name': 'us.amazon.nova-pro-v1:0'}, id='run--df1adc8e-68d5-42e2-83d6-507ae253bd6d-0', tool_calls=[{'name': 'remediation_strategy_from_monitoring', 'args': {'state': {'event': 'user attempting to break into AWS account'}}, 'id': 'tooluse_hkv-SR2TS32o5rsfppQyfg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 664, 'output_tokens': 105, 'total_tokens': 769, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), ToolMessage(content=\"{'messages': [AIMessage(content='No monitoring report found to search for remediation steps.', additional_kwargs={}, response_metadata={})], 'workflow': {}}\", name='remediation_strategy_from_monitoring', id='a5c40b56-d380-4cb6-8f11-5108dcac8513', tool_call_id='tooluse_hkv-SR2TS32o5rsfppQyfg'), AIMessage(content=' - The generated text has been blocked by our content filters.', additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '18970511-df59-4ff3-a828-933ac0a4cb96', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Tue, 17 Jun 2025 12:25:25 GMT', 'content-type': 'application/json', 'content-length': '253', 'connection': 'keep-alive', 'x-amzn-requestid': '18970511-df59-4ff3-a828-933ac0a4cb96'}, 'RetryAttempts': 0}, 'stopReason': 'content_filtered', 'metrics': {'latencyMs': [3709]}, 'model_name': 'us.amazon.nova-pro-v1:0'}, id='run--75b26695-a2c9-4ac4-b6b7-9970392a87cb-0', usage_metadata={'input_tokens': 840, 'output_tokens': 0, 'total_tokens': 840, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]\n"
     ]
    }
   ],
   "source": [
    "content = \"\"\" \n",
    "Hi, Generate a report on a user trying to break into my AWS account\n",
    "\"\"\"\n",
    "# Invoke monitoring agent with the given message\n",
    "diagnosis_response = diagnosis_agent.invoke({\"messages\": [HumanMessage(content=content)]})\n",
    "print(diagnosis_response[\"messages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the resolution tools\n",
    "---\n",
    "\n",
    "In this portion of the notebook, we will create a sub agent that will come up with a resolution. In this case, we will create a simple ticket on JIRA that the agent will assign to someone to take a look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a small model to create and assign issues.\n",
    "resolution_llm = ChatBedrockConverse(\n",
    "    model_id = AMAZON_NOVA_MICRO_MODEL_ID,\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoscaling_client = boto3.client('autoscaling')\n",
    "ec2_client = boto3.client('ec2')\n",
    "lambda_client = boto3.client('lambda')\n",
    "ecs_client = boto3.client('ecs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(run_type=\"tool\", name=\"Search Tool\")\n",
    "def create_jira_issue(summary: str, description: str, project_key: str = 'AIRT', issue_type: str = \"Task\", assignee: str = None):\n",
    "    \"\"\"\n",
    "    Creates a new issue in Jira with the specified details.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Creating Jira issue with project_key: {project_key}\")\n",
    "        \n",
    "        jira = JiraAPIWrapper()\n",
    "        \n",
    "        # Create the issue fields dictionary\n",
    "        issue_fields = {\n",
    "            \"summary\": summary,\n",
    "            \"description\": description,\n",
    "            \"issuetype\": {\"name\": issue_type},\n",
    "            \"project\": {\"key\": project_key},\n",
    "        }\n",
    "        if assignee:\n",
    "            issue_fields[\"assignee\"] = {\"name\": assignee}\n",
    "        \n",
    "        # Convert dictionary to JSON string\n",
    "        issue_fields_json = json.dumps(issue_fields)\n",
    "        print(f\"Sending JSON: {issue_fields_json}\")\n",
    "        \n",
    "        # Pass the JSON string to the issue_create method\n",
    "        result = jira.issue_create(issue_fields_json)\n",
    "        print(f\"CREATED THE JIRA TICKET! Check your JIRA dashboard.\")\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        return {\"error\": f\"Error creating Jira issue: {str(e)}\"}\n",
    "    \n",
    "resolution_toolkit = [create_jira_issue]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create agent and equip the agent with  new tool\n",
    "resolution_agent = create_react_agent(\n",
    "    resolution_llm,\n",
    "    tools=resolution_toolkit,\n",
    "    prompt=f\"\"\"You are an agent responsible for creating Jira tickets based on the diagnosis provided.\n",
    "    When given a diagnosis:\n",
    "    1. Extract the necessary information to create a Jira ticket.\n",
    "    2. Use the 'create_jira_issue' tool to create the ticket.\n",
    "    3. Confirm the creation of the ticket and if the diagnosis or information on \n",
    "    any security and compliance vulnerabilities. If there are any such compliance and security concerns from\n",
    "    the data that you have access to, create a report in the ticket description and steps to fix as well.\n",
    "    4. Create an in detail task, project key and how to diagnose it within the JIRA ticket.\n",
    "    the project key is {os.environ['PROJECT_KEY']}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resolution node for the workflow\n",
    "def resolution_node(state: Dict, config: Optional[Dict] = None) -> Dict:\n",
    "    \"\"\"Resolution agent node to create JIRA tickets.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Run the resolution agent\n",
    "    response = resolution_agent.invoke({\"messages\": messages})\n",
    "    \n",
    "    # Extract content from response based on its structure\n",
    "    if hasattr(response, \"content\"):\n",
    "        content = response.content\n",
    "    elif isinstance(response, str):\n",
    "        content = response\n",
    "    elif isinstance(response, dict) and \"content\" in response:\n",
    "        content = response[\"content\"]\n",
    "    elif hasattr(response, \"text\"):\n",
    "        content = response.text\n",
    "    elif isinstance(response, dict) and \"messages\" in response:\n",
    "        # Handle the case where response contains messages\n",
    "        last_message = response[\"messages\"][-1] if response[\"messages\"] else None\n",
    "        content = last_message.content if hasattr(last_message, \"content\") else str(last_message)\n",
    "    else:\n",
    "        content = str(response)\n",
    "    \n",
    "    # Update workflow state\n",
    "    workflow_state = state.get(\"workflow\", {})\n",
    "    workflow_state[\"resolution_complete\"] = \"RESOLUTION COMPLETE\" in content\n",
    "    \n",
    "    # Format response as AI message\n",
    "    ai_message = AIMessage(content=content)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": messages + [ai_message],\n",
    "        \"workflow\": workflow_state\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the supervisor agent and the graph and invoke all agents all together\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the workflow state\n",
    "class WorkflowState(TypedDict, total=False):\n",
    "    current_step: str\n",
    "    monitoring_complete: bool\n",
    "    diagnosis_complete: bool\n",
    "    resolution_complete: bool\n",
    "\n",
    "# Extended state that includes workflow state\n",
    "class AWSMonitoringState(MessagesState):\n",
    "    workflow: WorkflowState\n",
    "\n",
    "# Supervisor node determines next agent\n",
    "\n",
    "@traceable\n",
    "def supervisor_node(state):\n",
    "    messages = state.get(\"messages\", [])\n",
    "    workflow = state.get(\"workflow\", {\n",
    "        \"current_step\": \"monitoring_agent\",\n",
    "        \"monitoring_complete\": False,\n",
    "        \"diagnosis_complete\": False,\n",
    "        \"resolution_complete\": False\n",
    "    })\n",
    "    \n",
    "    # Check last message for completion markers\n",
    "    if messages and len(messages) >= 1 and isinstance(messages[-1], AIMessage):\n",
    "        content = messages[-1].content\n",
    "        if \"MONITORING COMPLETE\" in content.upper():\n",
    "            workflow[\"monitoring_complete\"] = True\n",
    "            workflow[\"current_step\"] = \"diagnosis_agent\"\n",
    "        elif \"DIAGNOSIS COMPLETE\" in content.upper():\n",
    "            workflow[\"diagnosis_complete\"] = True\n",
    "            workflow[\"current_step\"] = \"resolution_agent\"\n",
    "        elif \"RESOLUTION COMPLETE\" in content.upper():\n",
    "            workflow[\"resolution_complete\"] = True\n",
    "            workflow[\"current_step\"] = \"END\"\n",
    "    \n",
    "    # If resolution is happening and the agent has run at least once, consider it complete\n",
    "    if workflow[\"current_step\"] == \"resolution_agent\" and workflow[\"diagnosis_complete\"] and len(messages) >= 5:\n",
    "        workflow[\"resolution_complete\"] = True\n",
    "        workflow[\"current_step\"] = \"END\"\n",
    "    \n",
    "    # Determine the next step based on workflow state\n",
    "    next_step = workflow[\"current_step\"]\n",
    "    \n",
    "    print(f\"Supervisor routing to: {next_step}\")\n",
    "    print(f\"Workflow state: {workflow}\")\n",
    "    \n",
    "    if next_step == \"END\":\n",
    "        return {\"next\": END, \"workflow\": workflow}\n",
    "    return {\"next\": next_step, \"workflow\": workflow}\n",
    "\n",
    "# Create the graph\n",
    "workflow_graph = StateGraph(AWSMonitoringState)\n",
    "\n",
    "# Add nodes\n",
    "workflow_graph.add_node(\"supervisor\", supervisor_node)\n",
    "workflow_graph.add_node(\"monitoring_agent\", monitoring_node)\n",
    "workflow_graph.add_node(\"diagnosis_agent\", diagnosis_node)\n",
    "workflow_graph.add_node(\"resolution_agent\", resolution_node)\n",
    "\n",
    "# Set the entrypoint\n",
    "workflow_graph.set_entry_point(\"supervisor\")\n",
    "\n",
    "# Add conditional edges from supervisor\n",
    "workflow_graph.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    lambda state: state[\"next\"], \n",
    "    {\n",
    "        \"monitoring_agent\": \"monitoring_agent\",\n",
    "        \"diagnosis_agent\": \"diagnosis_agent\",\n",
    "        \"resolution_agent\": \"resolution_agent\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add edges from agents back to supervisor\n",
    "workflow_graph.add_edge(\"monitoring_agent\", \"supervisor\")\n",
    "workflow_graph.add_edge(\"diagnosis_agent\", \"supervisor\")\n",
    "workflow_graph.add_edge(\"resolution_agent\", \"supervisor\")\n",
    "aws_monitoring_workflow = workflow_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(aws_monitoring_workflow.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get inputs for (state): got an unexpected keyword argument 'config'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervisor routing to: monitoring_agent\n",
      "Workflow state: {'current_step': 'monitoring_agent', 'monitoring_complete': False, 'diagnosis_complete': False, 'resolution_complete': False}\n",
      "Fetching logs for the service: ['/aws/cloudtrail']\n",
      "fetching logs for log group /aws/cloudtrail/iam-events: {'logStreams': [{'logStreamName': '946538336216_CloudTrail_us-east-1_3', 'creationTime': 1750106778899, 'firstEventTimestamp': 1750106778828, 'lastEventTimestamp': 1750158912551, 'lastIngestionTime': 1750158912595, 'uploadSequenceToken': '49039859634068667161226731347941268542724002964696557450', 'arn': 'arn:aws:logs:us-east-1:946538336216:log-group:/aws/cloudtrail/iam-events:log-stream:946538336216_CloudTrail_us-east-1_3', 'storedBytes': 0}, {'logStreamName': '946538336216_CloudTrail_us-east-1_4', 'creationTime': 1750106798128, 'firstEventTimestamp': 1750106798088, 'lastEventTimestamp': 1750134790974, 'lastIngestionTime': 1750134790997, 'uploadSequenceToken': '49039859634036604057862061912791264914232034269516621703', 'arn': 'arn:aws:logs:us-east-1:946538336216:log-group:/aws/cloudtrail/iam-events:log-stream:946538336216_CloudTrail_us-east-1_4', 'storedBytes': 0}, {'logStreamName': '946538336216_CloudTrail_us-east-1', 'creationTime': 1750106739752, 'firstEventTimestamp': 1750106889395, 'lastEventTimestamp': 1750134624164, 'lastIngestionTime': 1750134624234, 'uploadSequenceToken': '49039859634036382391813800832865552340377869515024328556', 'arn': 'arn:aws:logs:us-east-1:946538336216:log-group:/aws/cloudtrail/iam-events:log-stream:946538336216_CloudTrail_us-east-1', 'storedBytes': 0}, {'logStreamName': '946538336216_CloudTrail_us-east-1_2', 'creationTime': 1750106887715, 'firstEventTimestamp': 1750106887671, 'lastEventTimestamp': 1750134623203, 'lastIngestionTime': 1750134623246, 'uploadSequenceToken': '49039859634036381078536540997368670370783655949834479452', 'arn': 'arn:aws:logs:us-east-1:946538336216:log-group:/aws/cloudtrail/iam-events:log-stream:946538336216_CloudTrail_us-east-1_2', 'storedBytes': 0}], 'ResponseMetadata': {'RequestId': '7ee62929-3144-44e4-b855-bd407c2ceaa5', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '7ee62929-3144-44e4-b855-bd407c2ceaa5', 'content-type': 'application/x-amz-json-1.1', 'content-length': '1672', 'date': 'Tue, 17 Jun 2025 11:29:57 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get inputs for (state): got an unexpected keyword argument 'config'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervisor routing to: diagnosis_agent\n",
      "Workflow state: {'current_step': 'diagnosis_agent', 'monitoring_complete': True, 'diagnosis_complete': False, 'resolution_complete': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get inputs for (state): got an unexpected keyword argument 'config'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervisor routing to: resolution_agent\n",
      "Workflow state: {'current_step': 'resolution_agent', 'monitoring_complete': True, 'diagnosis_complete': True, 'resolution_complete': False}\n"
     ]
    },
    {
     "ename": "ModelErrorException",
     "evalue": "An error occurred (ModelErrorException) when calling the Converse operation: Model produced invalid sequence as part of ToolUse. Please refer to the model tool use troubleshooting guide.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModelErrorException\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[108]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m events \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevents\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Log the node being executed\u001b[39;49;00m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnode_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m.\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mFore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCYAN\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m[NODE: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnode_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m]\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mStyle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mRESET_ALL\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/code/Projects/Agentic_AI_AutoGen/AWSBedrock-ProjectAWSIncidentResponse/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2436\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2434\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2435\u001b[39m             loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2437\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2438\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2440\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2441\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2442\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2443\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2444\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[105]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mresolution_node\u001b[39m\u001b[34m(state, config)\u001b[39m\n\u001b[32m      4\u001b[39m messages = state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Run the resolution agent\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m response = \u001b[43mresolution_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Extract content from response based on its structure\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(response, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/code/Projects/Agentic_AI_AutoGen/AWSBedrock-ProjectAWSIncidentResponse/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2719\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2716\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] = []\n\u001b[32m   2717\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2719\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2720\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2723\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2724\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2725\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2728\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2729\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2730\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2731\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2732\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2733\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   2734\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/code/Projects/Agentic_AI_AutoGen/AWSBedrock-ProjectAWSIncidentResponse/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2436\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2434\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2435\u001b[39m             loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2437\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2438\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2440\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2441\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2442\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2443\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2444\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/code/Projects/Agentic_AI_AutoGen/AWSBedrock-ProjectAWSIncidentResponse/.venv/lib/python3.12/site-packages/langgraph/prebuilt/chat_agent_executor.py:505\u001b[39m, in \u001b[36mcreate_react_agent.<locals>.call_model\u001b[39m\u001b[34m(state, config)\u001b[39m\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_model\u001b[39m(state: StateSchema, config: RunnableConfig) -> StateSchema:\n\u001b[32m    504\u001b[39m     state = _get_model_input_state(state)\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     response = cast(AIMessage, \u001b[43mmodel_runnable\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    506\u001b[39m     \u001b[38;5;66;03m# add agent name to the AIMessage\u001b[39;00m\n\u001b[32m    507\u001b[39m     response.name = name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/code/Projects/Agentic_AI_AutoGen/AWSBedrock-ProjectAWSIncidentResponse/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:3047\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3045\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3046\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3049\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/code/Projects/Agentic_AI_AutoGen/AWSBedrock-ProjectAWSIncidentResponse/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:5430\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5423\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5424\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5425\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5428\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5429\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5430\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5431\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5432\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5433\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5434\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/code/Projects/Agentic_AI_AutoGen/AWSBedrock-ProjectAWSIncidentResponse/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:372\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    362\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    367\u001b[39m     **kwargs: Any,\n\u001b[32m    368\u001b[39m ) -> BaseMessage:\n\u001b[32m    369\u001b[39m     config = ensure_config(config)\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    371\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    382\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/code/Projects/Agentic_AI_AutoGen/AWSBedrock-ProjectAWSIncidentResponse/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:957\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    948\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    950\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    954\u001b[39m     **kwargs: Any,\n\u001b[32m    955\u001b[39m ) -> LLMResult:\n\u001b[32m    956\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/code/Projects/Agentic_AI_AutoGen/AWSBedrock-ProjectAWSIncidentResponse/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:776\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    775\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    782\u001b[39m         )\n\u001b[32m    783\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    784\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/code/Projects/Agentic_AI_AutoGen/AWSBedrock-ProjectAWSIncidentResponse/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1022\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1020\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1026\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/code/Projects/Agentic_AI_AutoGen/AWSBedrock-ProjectAWSIncidentResponse/.venv/lib/python3.12/site-packages/langchain_aws/chat_models/bedrock_converse.py:658\u001b[39m, in \u001b[36mChatBedrockConverse._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    656\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInput params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    657\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mUsing Bedrock Converse API to generate response\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m658\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconverse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbedrock_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    661\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mResponse from Bedrock: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    662\u001b[39m response_message = _parse_response(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/code/Projects/Agentic_AI_AutoGen/AWSBedrock-ProjectAWSIncidentResponse/.venv/lib/python3.12/site-packages/botocore/client.py:598\u001b[39m, in \u001b[36mClientCreator._create_api_method.<locals>._api_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    594\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    595\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() only accepts keyword arguments.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    596\u001b[39m     )\n\u001b[32m    597\u001b[39m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m598\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/code/Projects/Agentic_AI_AutoGen/AWSBedrock-ProjectAWSIncidentResponse/.venv/lib/python3.12/site-packages/botocore/context.py:123\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[32m    122\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/code/Projects/Agentic_AI_AutoGen/AWSBedrock-ProjectAWSIncidentResponse/.venv/lib/python3.12/site-packages/botocore/client.py:1061\u001b[39m, in \u001b[36mBaseClient._make_api_call\u001b[39m\u001b[34m(self, operation_name, api_params)\u001b[39m\n\u001b[32m   1057\u001b[39m     error_code = error_info.get(\u001b[33m\"\u001b[39m\u001b[33mQueryErrorCode\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info.get(\n\u001b[32m   1058\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCode\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1059\u001b[39m     )\n\u001b[32m   1060\u001b[39m     error_class = \u001b[38;5;28mself\u001b[39m.exceptions.from_code(error_code)\n\u001b[32m-> \u001b[39m\u001b[32m1061\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[32m   1062\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1063\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[31mModelErrorException\u001b[39m: An error occurred (ModelErrorException) when calling the Converse operation: Model produced invalid sequence as part of ToolUse. Please refer to the model tool use troubleshooting guide.",
      "During task with name 'agent' and id '4e48a05b-d409-58b8-a0c0-a2f43bdaf9d1'",
      "During task with name 'resolution_agent' and id '05bc73d3-6399-e358-f0b1-f4fe5e118f93'"
     ]
    }
   ],
   "source": [
    "txt = \"\"\"\n",
    "I want to check if my account has any security or compliance vulnerabilities. For this, \n",
    "I want to discover my iam logs for the past, let's say a week and then diagnose it. Any\n",
    "help would be great!\n",
    "\"\"\"\n",
    "\n",
    "# Run the workflow\n",
    "events = aws_monitoring_workflow.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": txt}]}, \n",
    "    {\"recursion_limit\": 10}\n",
    ")\n",
    "\n",
    "# Log and save the events\n",
    "logger.info(f\"{Fore.MAGENTA}=== STARTING AWS MONITORING WORKFLOW ==={Style.RESET_ALL}\")\n",
    "\n",
    "with open(\"output.txt\", \"a\") as file:\n",
    "    from datetime import datetime\n",
    "    \n",
    "    if events is not None:\n",
    "        for event in events:\n",
    "            # Log the node being executed\n",
    "            for node_name, node_output in event.items():\n",
    "                logger.info(f\"{Fore.CYAN}[NODE: {node_name}]{Style.RESET_ALL}\")\n",
    "                \n",
    "                # Special handling for supervisor node\n",
    "                if node_name == \"supervisor\":\n",
    "                    workflow_state = node_output.get(\"workflow\", {})\n",
    "                    logger.info(f\"{Fore.MAGENTA}Workflow State: {workflow_state}{Style.RESET_ALL}\")\n",
    "                else:\n",
    "                    # For agent nodes, pretty print the messages\n",
    "                    pretty_print_messages(node_output)\n",
    "                \n",
    "                # Save to file\n",
    "                file.write(f\"{datetime.now()} - {node_name}: {str(node_output)}\\n\")\n",
    "    else:\n",
    "        error_msg = \"Workflow events stream is None\"\n",
    "        logger.error(error_msg)\n",
    "        file.write(f\"{datetime.now()} - ERROR: {error_msg}\\n\")\n",
    "\n",
    "logger.info(f\"{Fore.MAGENTA}=== WORKFLOW COMPLETE ==={Style.RESET_ALL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Streamlit UI\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b76a88aa08f40789b0723248c0ea8ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<h1 style='text-align:center;'>AWS Security & Compliance Chatbot</h1><hr>\"), Output…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:=== STARTING AWS MONITORING WORKFLOW ===\n",
      "WARNING:langsmith.run_helpers:Failed to get inputs for (state): got an unexpected keyword argument 'config'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervisor routing to: monitoring_agent\n",
      "Workflow state: {'current_step': 'monitoring_agent', 'monitoring_complete': False, 'diagnosis_complete': False, 'resolution_complete': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:[NODE: supervisor]\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching logs for the service: ['/aws/dummy-security-logs']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:__main__:[NODE: monitoring_agent]\n",
      "WARNING:langsmith.run_helpers:Failed to get inputs for (state): got an unexpected keyword argument 'config'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervisor routing to: diagnosis_agent\n",
      "Workflow state: {'current_step': 'diagnosis_agent', 'monitoring_complete': True, 'diagnosis_complete': False, 'resolution_complete': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:[NODE: supervisor]\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:__main__:[NODE: diagnosis_agent]\n",
      "WARNING:langsmith.run_helpers:Failed to get inputs for (state): got an unexpected keyword argument 'config'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervisor routing to: resolution_agent\n",
      "Workflow state: {'current_step': 'resolution_agent', 'monitoring_complete': True, 'diagnosis_complete': True, 'resolution_complete': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:[NODE: supervisor]\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:__main__:[NODE: resolution_agent]\n",
      "WARNING:langsmith.run_helpers:Failed to get inputs for (state): got an unexpected keyword argument 'config'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervisor routing to: resolution_agent\n",
      "Workflow state: {'current_step': 'resolution_agent', 'monitoring_complete': True, 'diagnosis_complete': True, 'resolution_complete': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:[NODE: supervisor]\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:__main__:[NODE: resolution_agent]\n",
      "WARNING:langsmith.run_helpers:Failed to get inputs for (state): got an unexpected keyword argument 'config'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervisor routing to: END\n",
      "Workflow state: {'current_step': 'END', 'monitoring_complete': True, 'diagnosis_complete': True, 'resolution_complete': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:[NODE: supervisor]\n",
      "INFO:__main__:=== WORKFLOW COMPLETE ===\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from datetime import datetime\n",
    "from colorama import Fore, Style\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def pretty_print_messages(node_output):\n",
    "    \"\"\"Pretty print the messages to the logger (for internal logging).\"\"\"\n",
    "    for key, value in node_output.items():\n",
    "        logger.info(f\"    {key}: {value}\")\n",
    "\n",
    "# Create UI components\n",
    "heading = widgets.HTML(\"<h1 style='text-align:center;'>AWS Security & Compliance Chatbot</h1><hr>\")\n",
    "chat_output = widgets.Output(layout={'border': '1px solid black', 'height': '300px', 'overflow_y': 'auto'})\n",
    "\n",
    "# Create text input and send button for the bottom input area\n",
    "text_input = widgets.Text(\n",
    "    value=\"\"\"I want to check if my account has any security or compliance vulnerabilities. For this, \n",
    "I want to discover my iam logs for the past, let's say a week and then diagnose it. Any\n",
    "help would be great!\"\"\",\n",
    "    placeholder=\"Type your message here...\",\n",
    "    description=\"\",\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width=\"80%\")\n",
    ")\n",
    "send_button = widgets.Button(\n",
    "    description=\"Send\",\n",
    "    button_style=\"success\",\n",
    "    tooltip=\"Click to send your query\",\n",
    "    icon=\"paper-plane\",\n",
    "    layout=widgets.Layout(width=\"20%\")\n",
    ")\n",
    "\n",
    "def on_send_button_clicked(b):\n",
    "    # Get user's message from the input box.\n",
    "    user_msg = text_input.value.strip()\n",
    "    if not user_msg:\n",
    "        return  # Ignore empty messages\n",
    "\n",
    "    # Display the user's query in the chat log.\n",
    "    with chat_output:\n",
    "        print(f\"\\nUser: {user_msg}\\n\")\n",
    "    \n",
    "    # Prepare the payload as required by your workflow.\n",
    "    params = {\"messages\": [{\"role\": \"user\", \"content\": user_msg}]}\n",
    "    extra_params = {\"recursion_limit\": 10}\n",
    "    \n",
    "    # Log the start of the workflow invocation.\n",
    "    logger.info(f\"{Fore.MAGENTA}=== STARTING AWS MONITORING WORKFLOW ==={Style.RESET_ALL}\")\n",
    "    \n",
    "    # Run the workflow.\n",
    "    events = aws_monitoring_workflow.stream(params, extra_params)\n",
    "    \n",
    "    # Log events and save them to file.\n",
    "    with open(\"output.txt\", \"a\") as file:\n",
    "        if events is not None:\n",
    "            for event in events:\n",
    "                for node_name, node_output in event.items():\n",
    "                    logger.info(f\"{Fore.CYAN}[NODE: {node_name}]{Style.RESET_ALL}\")\n",
    "                    \n",
    "                    # Display node output in the chat UI.\n",
    "                    with chat_output:\n",
    "                        if node_name == \"supervisor\":\n",
    "                            workflow_state = node_output.get(\"workflow\", {})\n",
    "                            print(f\"[{node_name}] Workflow State: {workflow_state}\")\n",
    "                        else:\n",
    "                            for key, value in node_output.items():\n",
    "                                print(f\"[{node_name}] {key}: {value}\")\n",
    "                    \n",
    "                    # Save the event details to a file with a timestamp.\n",
    "                    file.write(f\"{datetime.now()} - {node_name}: {str(node_output)}\\n\")\n",
    "        else:\n",
    "            error_msg = \"Workflow events stream is None\"\n",
    "            logger.error(error_msg)\n",
    "            with chat_output:\n",
    "                print(error_msg)\n",
    "            file.write(f\"{datetime.now()} - ERROR: {error_msg}\\n\")\n",
    "    \n",
    "    logger.info(f\"{Fore.MAGENTA}=== WORKFLOW COMPLETE ==={Style.RESET_ALL}\")\n",
    "    \n",
    "    # Clear the input for the next query.\n",
    "    text_input.value = \"\"\n",
    "\n",
    "# Bind the send button to the callback.\n",
    "send_button.on_click(on_send_button_clicked)\n",
    "\n",
    "# Arrange the UI in a typical chat layout:\n",
    "# 1. A header at the top.\n",
    "# 2. The chat output in the middle.\n",
    "# 3. An input area (text input and send button) at the bottom.\n",
    "input_area = widgets.HBox([text_input, send_button])\n",
    "ui = widgets.VBox([heading, chat_output, input_area])\n",
    "display(ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
